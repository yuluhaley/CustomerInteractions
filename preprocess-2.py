# -*- coding: utf-8 -*-
"""preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QVbRxHO6BbP3S-UYuhepxUuj5SyJXizD
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing libraries
import pandas as pd
import numpy as np
import seaborn as sns                       #visualisation
import matplotlib.pyplot as plt             #visualisation
import plotly.graph_objects as go           #visulaisation
# %matplotlib inline
sns.set(color_codes=True)

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("online_shoppers_intention.csv")
df.head()

print(list(df.columns))

df.shape

df.info()

"""### EDA"""

count=df.groupby('Revenue').size()
plt.rcParams["figure.figsize"] = (5,5)
plt.pie(count.values,labels=count.index,textprops={'fontsize':10},autopct='%1.2f%%')
plt.title("Frequency Statistics for Revenue",fontsize=10)
plt.show()

df['OperatingSystems']=df['OperatingSystems'].astype("object")
df['Browser']=df['OperatingSystems'].astype("object")
df['Region']=df['Region'].astype("object")
df['TrafficType']=df['TrafficType'].astype("object")

### numbers identify the categories of each variable, don't imply numerical meaning

df.info()

df.describe()

plt.plot(np.array(df['ProductRelated']),marker='o',markersize=3)
plt.legend(['ProductRelated'])
plt.ylabel('Value')

# Frequency tables for each categorical feature
pd.crosstab(index = df['VisitorType'], columns = 'counts')

for column in df.select_dtypes(include=['object']).columns:
    display(pd.crosstab(index=df[column], columns='% observations', normalize='columns')*100)

visitor_counts = df.groupby(['Region', 'VisitorType']).size().unstack(fill_value=0)

# Summing up the total visitors for each region
total_visitors_per_region = visitor_counts.sum(axis=1)

# Sorting the regions based on the total number of visitors
sorted_regions = total_visitors_per_region.sort_values().index

# Reordering the data based on the sorted regions
sorted_visitor_counts = visitor_counts.reindex(sorted_regions)

# Removing the 'Other' visitor type from the data
filtered_visitor_counts = sorted_visitor_counts.drop(columns='Other', errors='ignore')

# Create the final bar chart with only new and returning visitors
plt.figure(figsize=(12, 8))
filtered_visitor_counts.plot(kind='barh', stacked=True, color=['lightgreen', 'coral'], ax=plt.gca())
plt.title('Number of New and Returning Visitors by Region (Sorted by Total Visitors)')
plt.xlabel('Number of Visitors')
plt.ylabel('Region (Sorted by Total Visitors)')
plt.legend(title='Visitor Type')
plt.tight_layout()

browser_usage = df.groupby('Region')['Browser'].value_counts(normalize=True).mul(100).unstack()

# Plotting the data
plt.figure(figsize=(12, 8))
sns.heatmap(browser_usage, annot=True, cmap='coolwarm', fmt='.1f')
plt.title('Browser Usage Percentage by Region')
plt.ylabel('Region')
plt.xlabel('Browser')
plt.show()

data = {
    'Month': ['Aug', 'Dec', 'Feb', 'Jul', 'June', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],
    'Percentage': [3.51176, 14.006488, 1.492295, 3.503650, 2.335766, 15.466342, 27.283049, 24.314680, 4.452555, 3.633414]
}

# Creating DataFrame
mth_df = pd.DataFrame(data)

# Converting 'Month' to a category type and specifying the order
month_order = ['Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
mth_df['Month'] = pd.Categorical(mth_df['Month'], categories=month_order, ordered=True)

# Sorting the DataFrame based on the month order
mth_df.sort_values('Month', inplace=True)

# Plotting the data
plt.figure(figsize=(10, 5))
plt.plot(mth_df['Month'], mth_df['Percentage'], marker='o')

plt.xlabel('Month')
plt.ylabel('Percentage')
plt.title('Percentage of Observations by Month ')
plt.show()

sns.countplot(x='VisitorType',data=df,hue='Revenue',palette='rainbow')
plt.title("Statistical chart between VisitorType and Revenue")
plt.show()

sns.countplot(x='SpecialDay',data=df,hue='Revenue',palette='rainbow')
plt.title("Statistical chart between SpecialDay and Revenue")
plt.show()

corr= df.corr()
corr

plt.figure(figsize=(10,10))
sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,cmap="BuGn",annot=True)

"""### Preprocess"""

df[df.duplicated()].shape

df = df.drop_duplicates()

df.shape

grouped_data = df.groupby('Region').mean()

mean_pagevalue = grouped_data[["PageValues"]].copy()
mean_pagevalue

# # 2. Irrelevant columns?
# df = df.drop(columns=['Make', 'Model','Popularity'], axis=1)

print(df.isnull().sum())

# from scipy.stats import iqr

# #for column in df.select_dtypes(include=['int64','float64']).columns:
#     IQR = iqr(df[column])
#     q3 = df[column].quantile(.75)
#     df = df[~(df[column] > (q3 + 1.5 * IQR))]

df.shape

df_numerical=df[['Administrative', 'Administrative_Duration', 'Informational',
       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',
       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']]
df_categorical=df[['Month','OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType',
       'Weekend', 'Revenue']]
from sklearn.preprocessing import StandardScaler
scaled_X=StandardScaler().fit_transform(df_numerical)
scaled_X

scaled_X = pd.DataFrame(scaled_X, columns=df_numerical.columns) # transform into a dataframe and add column names
scaled_X

df_categorical.reset_index(inplace=True)

df_categorical=df_categorical.drop(['index'],axis=1)

df=pd.concat([scaled_X, df_categorical], axis=1)

df.shape

# Using get_dummies
for column in df.select_dtypes(include=['object']).columns:
    dum = pd.get_dummies(df[column], prefix=column, drop_first=True)
    df = pd.concat([df, dum], axis=1)

df.head()

df.to_csv('online_shoppers_preoprocessed.csv', index=False)

