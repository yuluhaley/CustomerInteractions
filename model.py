# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ipRW39r_YliSvVO-N8uwmTBLA_orvQjV

# 1 Import packages and load dataset
"""

import pandas as pd
import numpy as np
from google.colab import files
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Lasso
from sklearn.decomposition import PCA
import math
from scipy import stats
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import precision_recall_curve

from sklearn.neighbors import KNeighborsClassifier
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import average_precision_score

uploaded = files.upload()

"""## Orginal dataset"""

shoppers_ori = pd.read_csv("online_shoppers_intention.csv")

shoppers_ori

"""## Cleaned dataset"""

shoppers = pd.read_csv("online_shoppers_preprocessed.csv")

shoppers.columns

shoppers.drop(["Month", "OperatingSystems", "Browser", "Region", "TrafficType", "VisitorType"], axis = 1, inplace = True)

shoppers

X = shoppers.loc[:, ~shoppers.columns.isin(['Revenue'])]

y = shoppers["Revenue"]

X

y = y.replace(False, 0)
y = y.replace(True, 1)

y

"""# 2 Data Preprocessing

Note: I have tried to do the feature selection and run the model based on the selected features, but the area under the precision-recall curve turns out to be very low (around 0.22) (use logistic regression to test this), so I decide not to do any feature selection.

## Feature selection using lasso
"""

ls = Lasso(alpha=0.05)
model = ls.fit(X,y)

summary_X = pd.DataFrame(list(zip(X.columns,model.coef_)), columns = ['predictor','coefficient'])

summary_X

selected_X = summary_X[summary_X["coefficient"] != 0].reset_index(drop = True)

print(selected_X.shape[0])

selected_X

"""## Feature selection using z score (linear regression)"""

def get_z(X, y, features, N):
  """
  Find the value of zd, return a list of zd's.
  """
  z = []
  for i in range(len(features)):
    xd = X.loc[:,features[i]].to_numpy()
    xd_std = (xd - xd.mean()) / (xd.std())
    zd = np.transpose(xd)@y/ math.sqrt(N)
    z.append(zd)
  return z

Z = get_z(X, y, X.columns, X.shape[0])
Z_abs = np.abs(Z)

p_value = stats.norm.sf(Z_abs)*2
p_value

alpha1 = 0.1
alpha2 = 0.05
alpha3 = 0.01
alpha4 = 0.001
alpha5 = 0.0001
alpha6 = 0.00001
alpha7 = 0.000001
alpha8 = 0.0000001

def hypothesis_testing(alpha, p_val):
  """
  Perform hypothesis testing.
  If p_val < alpha, reject H0, else accept H0.
  Return index of p_val that is less than alpha.
  """
  index = []
  for i in range(len(p_val)):
    if p_val[i] < alpha:
      index.append(i)
  return index

select_ind = np.array(hypothesis_testing(alpha2, p_value))
select_feat_1 = X.columns[select_ind]

select_feat_1

"""## Feature selection using MI score"""

mi_scores = mutual_info_classif(X, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=662)

print(mi_scores)

selected_num1 = 20
selected_num2 = 30
selected_num3 = 40

selected_ind = np.argsort(mi_scores)[0:selected_num2]
selected_ind

selected_features = X.columns[selected_ind]
selected_features

X_selected = X[selected_features]

X_selected

"""# 3 Fitting model"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 662)

"""## KNN

### Trial 1
"""

knn = KNeighborsClassifier()
knn_params = [{'n_neighbors': [10, 50, 100, 150, 200],
               'p': [1, 2]}] # p=1: manhatten distance; p=2: euclidean distance

clf = GridSearchCV(knn, knn_params, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="KNN")
_ = display.ax_.set_title("Precision-Recall curve")

"""### Trial 2"""

knn = KNeighborsClassifier()
knn_params = [{'n_neighbors': [200, 250, 300, 350],
               'p': [1, 2]}] # p=1: manhatten distance; p=2: euclidean distance

clf = GridSearchCV(knn, knn_params, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="KNN")
_ = display.ax_.set_title("Precision-Recall curve")

"""## Logistic regression

### Trial 1
"""

# Run logistic regression
logistic = LogisticRegression(random_state=662)
log_params = [{'tol': [1e-4, 1e-3, 1e-2],
               'max_iter': [300, 500, 700, 900]}]

clf = GridSearchCV(logistic, log_params, cv = 5, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)

print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="LogisticRegression")
_ = display.ax_.set_title("Precision-Recall curve")

"""### Trial 2"""

logistic = LogisticRegression(random_state=662)
log_params = [{'tol': [1e-6, 1e-5, 1e-4],
               'max_iter': [100, 200, 300, 400]}]

clf = GridSearchCV(logistic, log_params, cv = 5, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="LogisticRegression")
_ = display.ax_.set_title("Precision-Recall curve")

"""## Gradient Boosting

### Trial 1
"""

gbt = GradientBoostingClassifier(random_state=0)
boosting_params = [{'n_estimators': [50, 100, 150, 200],
                    'max_features': [4, 5, 6],
                    'min_samples_leaf': [10, 100, 200],
                    'learning_rate': [0.01, 0.05, 0.1],
                    'max_depth': [1, 3, 5]}]

clf = GridSearchCV(gbt, boosting_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

results = clf.cv_results_

print(clf.best_params_)

print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="GradientBoosting")
_ = display.ax_.set_title("Precision-Recall curve")

"""### Trial 2"""

gbt = GradientBoostingClassifier(random_state=0)
boosting_params = [{'n_estimators': [180, 200, 250, 300],
                    'max_features': [6, 10, 20, 30],
                    'min_samples_leaf': [10, 25, 50],
                    'learning_rate': [0.02, 0.05, 0.07],
                    'max_depth': [5, 7, 9]}]

clf = GridSearchCV(gbt, boosting_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="GradientBoosting")
_ = display.ax_.set_title("Precision-Recall curve")

"""## Random Forest

### Trial 1
"""

rfc = RandomForestClassifier(random_state=662)
forest_params = [{'n_estimators': [50, 100, 150, 200, 250],
                  'max_features': [3, 5, 7, 9, 11],
                  'min_samples_leaf': [10, 100, 200],
                  'criterion': ['gini', 'entropy', 'log_loss']}]

clf = GridSearchCV(rfc, forest_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="Random Forest")
_ = display.ax_.set_title("Precision-Recall curve")

"""### Trial 2"""

rfc = RandomForestClassifier(random_state=662)
forest_params = [{'n_estimators': [150, 200, 250, 300, 350, 400],
                  'max_features': [9, 11, 13, 15],
                  'min_samples_leaf': [10, 25, 50, 75],
                  'criterion': ['gini', 'entropy', 'log_loss']}]

clf = GridSearchCV(rfc, forest_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="Random Forest")
_ = display.ax_.set_title("Precision-Recall curve")

"""### Trial 3"""

rfc = RandomForestClassifier(random_state=662)
forest_params = [{'n_estimators': [200, 220, 250],
                  'max_features': [12, 13, 14],
                  'min_samples_leaf': [1, 5, 10, 20],
                  'criterion': ['gini', 'entropy', 'log_loss']}]

clf = GridSearchCV(rfc, forest_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay

display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="Random Forest")
_ = display.ax_.set_title("Precision-Recall curve")

"""## MLP

I did some random trials on the number of layers, found that when added to 4 hidden layers, the model starts to overfit (area under precision-recall curve decreases), so in this section, the max. number of hidden layers is 3 (equivalent to total # of layers = 5 including the input layer and output layer).

### no hidden layer
"""

mlp1 = MLPClassifier(random_state=0, shuffle = True, max_iter = 600, hidden_layer_sizes=(), batch_size = 256)
mlp1_params = [{'activation': ['relu', 'tanh', 'identity'],
               'alpha': [1e-3, 1e-2, 1e-1],
               'momentum': [0.1, 0.5, 0.9],
               'learning_rate_init': [1e-3, 5e-3, 1e-2]}]

clf = GridSearchCV(mlp1, mlp1_params, cv = 3, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="MLP with 0 hidden layer")
_ = display.ax_.set_title("Precision-Recall curve")

"""### 1 hidden layer

Note: to save time on training the model, I did some random trials to test the performance of different activation functions (relu, tanh, logistic). In most cases, ReLU performs better, so below I didn't tune the activation function, instead, just set ReLU as the activation function for all cases. And the same thing for 2-hidden layers and 3-hidden layers.
"""

mlp2 = MLPClassifier(random_state=662, shuffle = True, max_iter = 600, batch_size = 256, activation = "relu")
mlp2_params = [{'hidden_layer_sizes': [(128,), (256,), (512,)],
                'alpha': [1e-3, 1e-2],
                'momentum': [0.1, 0.2, 0.5],
                'learning_rate_init': [1e-2, 2e-2, 5e-2]}]

clf = GridSearchCV(mlp2, mlp2_params, cv = 2, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="MLP with 1 hidden layer")
_ = display.ax_.set_title("Precision-Recall curve")

"""random test template"""

mlp = MLPClassifier(random_state=662,
                    shuffle = True,
                    max_iter = 600,
                    batch_size = 128,
                    hidden_layer_sizes = (128,),
                    activation = "relu",
                    alpha = 1e-2,
                    momentum = 0.2,
                    learning_rate_init = 1e-2)

mlp.fit(X_train, y_train)

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    mlp, X_test, y_test, name="MLP with 0 hidden layer")
_ = display.ax_.set_title("Precision-Recall curve")

"""### 2 hidden layers"""

mlp3 = MLPClassifier(random_state=662, shuffle = True, max_iter = 600, batch_size = 256, activation = 'relu')
mlp3_params = [{'hidden_layer_sizes': [(128,128), (256,256), (512,512)],
                'alpha': [1e-3, 1e-2],
                'momentum': [0.1, 0.2, 0.5],
                'learning_rate_init': [1e-2, 2e-2, 5e-2]}]

clf = GridSearchCV(mlp3, mlp3_params, cv = 2, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="MLP with 2 hidden layers")
_ = display.ax_.set_title("Precision-Recall curve")

"""### 3 hidden layers"""

mlp4 = MLPClassifier(random_state=662, shuffle = True, max_iter = 600, batch_size = 256, activation = 'relu')
mlp4_params = [{'hidden_layer_sizes': [(128,128,32), (256,256,32), (512,512,32)],
                'alpha': [1e-3, 1e-2],
                'momentum': [0.1, 0.2, 0.5],
                'learning_rate_init': [1e-2, 2e-2, 5e-2]}]

clf = GridSearchCV(mlp4, mlp4_params, cv = 2, scoring='average_precision', verbose = True)
clf.fit(X_train, y_train)

print(clf.best_params_)
print(clf.best_score_)

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, name="MLP with 3 hidden layers")
_ = display.ax_.set_title("Precision-Recall curve")

"""# 4 Conclusion

By comparing the area under the precision-recall curve, we could observe that Gradient Boosting and Random Forest both outperform other models. However, since it took a shorter period to train the Random Forest, Random Forest is considered more efficient.

The best model would Random Forest Trial 3 with {'criterion' (loss function): 'entropy', 'max_features' (max number of features that use to make a split): 13, 'min_samples_leaf' (min number of data points in a leaf node): 5, 'n_estimators' (number of trees): 250}.

# 5 The final selected model
"""

rfc = RandomForestClassifier(random_state=662,
                             criterion='entropy',
                             max_features = 13, # 13
                             min_samples_leaf=5, # 5
                             n_estimators=250) # 250
rfc.fit(X_train, y_train)

y_pred = rfc.predict(X_test)

"""## Precision-Recall Curve"""

from sklearn.metrics import PrecisionRecallDisplay
display = PrecisionRecallDisplay.from_estimator(
    rfc, X_test, y_test, name="Random Forest")
_ = display.ax_.set_title("Precision-Recall curve")

"""## Accuracy"""

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_pred)

from sklearn.metrics import precision_recall_fscore_support
precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)

precision

recall

f1

"""## Analyze on the misclassification points"""

misclass_ind = y_test[y_test != y_pred].index

misclass_X = X_test.loc[misclass_ind,:]

misclass_X

misclass_y = y_test[y_test != y_pred]

misclass_y

plt.hist(misclass_y.to_numpy())
plt.ylabel('Quatity')
plt.xlabel('Class')

"""More misclassification for Class 1."""

misclass_X.describe().drop("count", axis = 0).loc[:, (misclass_X != 0).any(axis=0)]
# drop the "count" row since all equals to 381 (the number of misclassification points)
# drop all the zeros columns

"""Analyze specifically on Class 0"""

misclass_y_0 = misclass_y[misclass_y == 0]

misclass_y_0

misclass_X_0 = misclass_X.loc[misclass_y_0.index, :]

misclass_X_0.describe().drop("count", axis = 0).loc[:, (misclass_X_0 != 0).any(axis=0)]
# drop the "count" row since all equals to 381 (the number of misclassification points)
# drop all the zeros columns

"""Analyze specifically on Class 1"""

misclass_y_1 = misclass_y[misclass_y == 1]

misclass_y_1

misclass_X_1 = misclass_X.loc[misclass_y_1.index, :]

misclass_X_1.describe().drop("count", axis = 0).loc[:, (misclass_X_1 != 0).any(axis=0)]
# drop the "count" row since all equals to 381 (the number of misclassification points)
# drop all the zeros columns